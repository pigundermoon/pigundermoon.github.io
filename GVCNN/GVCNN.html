
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0055)http://www.icst.pku.edu.cn/course/icb/Projects/oad.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="language" content="english">
<title>One-for-All: Grouped Variation Network Based Fractional Interpolation in Video Coding</title>
<link rel="stylesheet" type="text/css" href="./GVCNN/project.css">
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>

<body>
<div id="main">
  
	<div class="content"><br>
		<h1>One-for-All: Grouped Variation Network Based Fractional Interpolation in Video Coding</h1>
		<div class="authors">
        	<div class="author">
				 <a href="" style="text-decoration: none">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp</a>
			</div>
			<div class="author">
				 <a href="http://www.icst.pku.edu.cn/struct/people/liujiaying.html" style="text-decoration: none">Jiaying Liu</a>
			</div>
			<div class="author">
				 <a href="http://www.icst.pku.edu.cn/struct/people/xsf.html" style="text-decoration: none">Sifeng Xia</a>
			</div>        
			<div class="author">
				 <a href="http://www.icst.pku.edu.cn/course/icb/people/whyang.html" style="text-decoration: none">Wenhan Yang</a>
		    </div>
			<div class="author">
				 <a href="" style="text-decoration: none">Mading Li</a>
			</div>
			<div class="author">
				 <a href="" style="text-decoration: none">Dong Liu</a>
			</div>

		</div>
		<br>
	  	<p class="banner" align="center"><i>IEEE Trans. on Image Processing (TIP)</i>, May 2019. </p>


		<div class="Abstract sec">
			<h2>Abstract</h2>
			<div class="desp">
				<p style="text-align:justify">
				 Fractional interpolation is used to provide sub-pixel
level references for motion compensation in the inter prediction of
video coding, which attempts to remove temporal redundancy in
video sequences. Traditional handcrafted fractional interpolation
filters face the challenge of modeling discontinuous regions in
videos, while existing deep learning based methods are either
designed for a single quantization parameter (QP), only generate
half-pixel samples, or need to train a model for each subpixel
position. In this paper, we present a one-for-all fractional
interpolation method based on grouped variation convolutional
neural network (GVCNN). Our method can deal with video
frames coded using different QPs and is capable of generating
all sub-pixel positions at one sub-pixel level. Also, by predicting
variations between integer-position pixels and sub-pixels, our
network offers more expressive power. Moreover, we perform
specific measurements in training data generation to simulate
practical situations in video coding, including blurring the downsampled
sub-pixel samples to avoid aliasing effects and coding
integer pixels to simulate reconstruction errors. In addition,
we analyze the impact of the size of blur kernels theoretically.
Experimental results verify the efficiency of GVCNN. Compared
with HEVC, our method achieves 2:2% in bit saving on average
and up to 5:2% under low-delay P configuration.</p>
			</div>
            <h2>Framework</h2>
			<div align="center" id="flowchart">
		  		<img src="./img/net.PNG" width="100%">
		  		<p style="text-align: justify">Figure. 1. Framework of the proposed GVCNN. The network first extracts feature maps from the integer-position sample. Then the group variations that identify
the differences between different sub-pixel position samples and the integer-position sample are inferred using the same feature maps. Final results of sub-pixel
position samples are naturally obtained by adding the variations back to the integer-position sample.
</div>
		</div>
        <h2>Results</h2>
			<div align="center" id="res">
			<p style="text-align: center">Table 1: BD-rate reduction of the proposed method compared to HEVC.
			<img src="./img/res.PNG" width="75%">
		  	<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:5px 15px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:0px 0px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg .tg-s6z2{text-align:center}
</style>
	
</div>

		<div class="download sec">
			<h2>Download</h2>
			<div>
				<li><strong><a href="https://ieeexplore.ieee.org/document/8543165">Paper</a></strong>  </li>
				<li><strong><a href="https://github.com/pigundermoon/GVCNN">Code</a></strong>  </li>
				<!--<li><strong>Supplementary Material</strong>: <a href="http://www.icst.pku.edu.cn/course/icb/Projects/MALDEC_files/files/supp.pdf">pdf</a></li>-->
			</div>
		</div>

	  <div class="citation sec">
			<h2>Citation</h2>
			<p class="bibtex">@ARTICLE{GVCNN, 
&nbsp;&nbsp; author={J. Liu and S. Xia and W. Yang and M. Li and D. Liu}, 
&nbsp;&nbsp; journal={IEEE Transactions on Image Processing}, 
&nbsp;&nbsp; title={One-for-All: Grouped Variation Network Based Fractional Interpolation in Video Coding}, 
&nbsp;&nbsp; year={2019}, 
&nbsp;&nbsp; }
			</p>
	  </div>

<!-- 		<div class="experiments sec">
			<h2>Additional Results</h2>
			<div id="images">
				<h3>Action Detection Performance</h3>
				<div align="center" id="table">
					<p>Table 1. F 1âˆ’Score on OAD dataset</p>
					<img src='OAD/figures/OAD_table.png' width='50%' >
				</div>
			</div>
		</div>
		<br></br> -->


<div class="citation sec">
    <h2>&nbsp;</h2>
    </div>
  </div>
</div>


</body></html>